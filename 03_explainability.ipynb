{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sameeksha2597/AICourseProject/blob/main/03_explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXKErj5lePlh",
        "outputId": "a5913813-e1d1-4524-fccc-3a0f3033de56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded 10 samples from GLUE SST-2 validation set:\n",
            "\n",
            "1. it 's a charming and often affecting journey .  (Label: 1)\n",
            "2. unflinchingly bleak and desperate  (Label: 0)\n",
            "3. allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .  (Label: 1)\n",
            "4. the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .  (Label: 1)\n",
            "5. it 's slow -- very , very slow .  (Label: 0)\n",
            "6. although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .  (Label: 1)\n",
            "7. a sometimes tedious film .  (Label: 0)\n",
            "8. or doing last year 's taxes with your ex-wife .  (Label: 0)\n",
            "9. you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance .  (Label: 1)\n",
            "10. in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey .  (Label: 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating LIME explanations...\n",
            "\n",
            "\n",
            "\n",
            "LIME → Sentence 1: it 's a charming and often affecting journey . \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install lime shap datasets transformers torch --quiet\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import shap\n",
        "import numpy as np\n",
        "import torch\n",
        "from IPython.display import display, HTML\n",
        "dataset = load_dataset(\"glue\", \"sst2\", split=\"validation[:10]\")\n",
        "\n",
        "print(\"Loaded 10 samples from GLUE SST-2 validation set:\\n\")\n",
        "for i, example in enumerate(dataset):\n",
        "    print(f\"{i+1}. {example['sentence']} (Label: {example['label']})\")\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=model_name, return_all_scores=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "labels = [\"NEGATIVE\", \"POSITIVE\"]\n",
        "def predict_proba(texts):\n",
        "    outputs = classifier(texts)\n",
        "    probs = []\n",
        "    for out in outputs:\n",
        "        probs.append([out[0][\"score\"], out[1][\"score\"]])\n",
        "    return np.array(probs)\n",
        "\n",
        "print(\"Generating LIME explanations...\")\n",
        "print(\"\\n\")\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=labels)\n",
        "\n",
        "for i in range(10):\n",
        "    text = dataset[i][\"sentence\"]\n",
        "    print(f\"\\nLIME → Sentence {i+1}: {text}\")\n",
        "\n",
        "    exp = explainer.explain_instance(text, predict_proba, num_features=8)\n",
        "\n",
        "    html_file = f\"lime_result_{i+1}.html\"\n",
        "    exp.save_to_file(html_file)\n",
        "\n",
        "    display(HTML(exp.as_html()))\n",
        "print(\"Generating SHAP explanations\")\n",
        "\n",
        "def f(x):\n",
        "    inputs = tokenizer(list(x), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        return torch.nn.functional.softmax(outputs.logits, dim=1).numpy()\n",
        "\n",
        "explainer_shap = shap.Explainer(f, tokenizer)\n",
        "\n",
        "for i in range(10):\n",
        "    text = dataset[i][\"sentence\"]\n",
        "    print(f\"\\nSHAP → Sentence {i+1}: {text}\")\n",
        "    shap_values = explainer_shap([text])\n",
        "    shap.plots.text(shap_values[0])\n",
        "\n",
        "\n"
      ]
    }
  ]
}